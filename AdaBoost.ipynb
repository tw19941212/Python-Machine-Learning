{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "# 利用AdaBoost元算法提高分类性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**元算法(meta-algorithm)是对其他算法进行组合的一种方式**。集中关注一个称作**AdaBoost的最流行的元算法**。某些人认为AdaBoost是最好的监督学习的方法，所以该方法是机器学习工具箱中最强有力的工具之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "先讨论不同分类器的集成方法，然后**主要关注boosting方法及其代表分类器Adaboost**。接下来AdaBoost算法将应用在上述单层决策树分类器之上。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "最后讨论所有分类器都会遇到的一个通用问题：非均衡分类问题。**需要利用修改后的指标来评价分类器的性能**。而就这个问题而言，并非AdaBoost所独用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 基于数据集多重抽样的分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "自然可以将不同的分类器组合起来，而这种组合结果则被称为集成方法(ensemble method)或者元算法。**使用集成方法时会有多种形式**：可以是不同算法的集成，也可以是同一算法在不同设置下的集成，还可以是数据集不同部分分配给不同分类器之后的集成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "|AdaBoost||\n",
    "|:-|:-|\n",
    "|优点|泛化错误率低，易编码，可以应用在大部分分类器上，无参数调整|\n",
    "|缺点|对离群点敏感|\n",
    "|适用数据类型|数值型和标称型数据|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### bagging：基于数据随机重抽样的分类器构建方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "自举汇聚法(bootstrap aggregating)，也称为**bagging方法，是在从原始数据集选择S次后得到S个新数据集的一种技术**。新数据集和原数据集的大小相等。随机抽样---可以多次地选择同一样本。这一性质就允许新数据集中可以有重复的值，而原始数据集的某些值在新集合中则不再出现。  \n",
    "在S个数据集建好之后，将某个学习算法分别作用于每个数据集就得到了S个分类器。当我们要对新数据进行分类时，就可以应用这S个分类器进行分类。与此同时，选择分类器投票结果中最多的类别作为最后的分类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**不论是在boosting还是bagging当中，所使用的多个分类器的类型都是一致的**前者不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。**boosting是通过集中关注被已有分类器错分的那些数据来获得新的分类器。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "由于boosting分类的结果是基于所有分类器的加权求和结果的，bagging中的分类器权重是相等的，而**boosting中的分类器权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。**  \n",
    "boosting方法拥有多个版本，本章将只关注其中一个最流行的版本AdaBoost。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "|AdaBoost的一般流程||\n",
    "|:-|:-|\n",
    "|收集数据|可以使用任意方法|\n",
    "|准备数据|依赖于所使用的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器，第2章到第6章中的任一分类器都可以充当弱分类器。作为弱分类器，简单分类器的效果更好|\n",
    "|分析数据|可以使用任意方法|\n",
    "|训练算法|AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器|\n",
    "|测试算法|计算分类的错误率|\n",
    "|使用算法|同SVM一样，AdaBoost预测两个类别中的一个。如果想把它应用到多个类别的场合，那么就要像多类SVM中的做法一样对AdaBoost进行修改|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 训练算法：基于错误提升分类器的性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "能否使用弱分类器和多个实例来构建一个强分类器？这里的“弱”意味着分类器的性能比随机猜测要略好(>0.5)，AdaBoost算法即脱胎于上述理论问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "AdaBoost是adaptive boosting(自适应boosting)的缩写，**其运行过程如下**：训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量D。一开始，这些权重都初始化成相等值。首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。**在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本的权重将会提高。**为了从所有弱分类器中得到最终的分类结果，**AdaBoost为每个分类器都分配了一个权重值alpha，这些alpha值是基于每个弱分类器的错误率进行计算的。**其中，错误率ε的定义为：\n",
    "$$\\epsilon =\\frac{未正确分类的样本数目}{所以样本数目}$$\n",
    "而alpha的计算公式如下:\n",
    "$$\\alpha = \\frac {1} {2} ln\\frac {1-\\epsilon} {\\epsilon} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "![图7-1](https://github.com/tw19941212/Graph-bed/raw/master/%E5%9B%BE7-1AdaBoost%E7%AE%97%E6%B3%95%E7%9A%84%E7%A4%BA%E6%84%8F%E5%9B%BE%E3%80%82%E5%B7%A6%E8%BE%B9%E6%98%AF%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E5%85%B6%E4%B8%AD%E7%9B%B4%E6%96%B9%E5%9B%BE%E7%9A%84%E4%B8%8D%E5%90%8C%E5%AE%BD%E5%BA%A6%E8%A1%A8%E7%A4%BA%E6%AF%8F%E4%B8%AA%E6%A0%B7%E4%BE%8B%E4%B8%8A%E7%9A%84%E4%B8%8D%E5%90%8C%E6%9D%83%E9%87%8D%E3%80%82%E5%9C%A8%E7%BB%8F%E8%BF%87%E4%B8%80%E4%B8%AA%E5%88%86%E7%B1%BB%E5%99%A8%E4%B9%8B%E5%90%8E%EF%BC%8C%E5%8A%A0%E6%9D%83%E7%9A%84%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%9C%E4%BC%9A%E9%80%9A%E8%BF%87%E4%B8%89%E8%A7%92%E5%BD%A2%E4%B8%AD%E7%9A%84alpha%E5%80%BC%E8%BF%9B%E8%A1%8C%E5%8A%A0%E6%9D%83%E3%80%82%E6%AF%8F%E4%B8%AA%E4%B8%89%E8%A7%92%E5%BD%A2%E4%B8%AD%E8%BE%93%E5%87%BA%E7%9A%84%E5%8A%A0%E6%9D%83%E7%BB%93%E6%9E%9C%E5%9C%A8%E5%9C%86%E5%BD%A2%E4%B8%AD%E6%B1%82%E5%92%8C%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%BE%97%E5%88%B0%E6%9C%80%E7%BB%88%E7%9A%84%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C.jpg)\n",
    "左边是数据集，其中直方图的不同宽度表示每个样例上的不同权重。在经过一个分类器之后，加权的预测结果会通过三角形中的alpha值进行加权。每个三角形中输出的加权结果在圆形中求和，从而得到最终的输出结果AdaBoost算法的示意图。左边是数据集，其中直方图的不同宽度表示每个样例上的不同权重。在经过一个分类器之后，加权的预测结果会通过三角形中的alpha值进行加权。每个三角形中输出的加权结果在圆形中求和，从而得到最终的输出结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "计算出alpha值之后，可以对权重向量D进行更新，以使得那些正确分类的样本的权重降低而错分样本的权重升高。**D的计算方法如下。**  \n",
    "如果某个样本被正确分类，那么该样本的权重更改为：\n",
    "$$D_{i}^{t+1}=\\frac{D_{i}^{t}e^{-a}}{Sum(D)}$$\n",
    "而如果某个样本被错分，那么该样本的权重更改为：\n",
    "$$D_{i}^{t+1}=\\frac{D_{i}^{t}e^{a}}{Sum(D)}$$\n",
    "在计算出D之后，AdaBoost又开始进入下一轮迭代。AdaBoost算法会不断地重复训练和调整权重的过程，直到训练错误率为0或者弱分类器的数目达到用户的指定值为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 基于单层决策树构建弱分类器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "单层决策树(decision stump，也称决策树桩)是一种简单的决策树。仅基于单个特征来做决策。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T07:00:35.359058Z",
     "start_time": "2018-07-15T07:00:35.355055Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 简单数据集确保算法准备就绪\n",
    "\n",
    "\n",
    "def loadSimpData():\n",
    "    dataMat = np.matrix([[1.,  2.1],\n",
    "                        [2.,  1.1],\n",
    "                        [1.3,  1.],\n",
    "                        [1.,  1.],\n",
    "                        [2.,  1.]])\n",
    "    classLabels = [1.0, 1.0, -1.0, -1.0, 1.0]\n",
    "    return dataMat, classLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "![图7-2](https://github.com/tw19941212/Graph-bed/raw/master/%E5%9B%BE7-2%E7%94%A8%E4%BA%8E%E6%A3%80%E6%B5%8BAdaBoost%E6%9E%84%E5%BB%BA%E5%87%BD%E6%95%B0%E7%9A%84%E7%AE%80%E5%8D%95%E6%95%B0%E6%8D%AE%E3%80%82%E8%BF%99%E4%B8%8D%E5%8F%AF%E8%83%BD%E4%BB%85%E4%BB%85%E9%80%9A%E8%BF%87%E5%9C%A8%E6%9F%90%E4%B8%AA%E5%9D%90%E6%A0%87%E8%BD%B4%E4%B8%8A%E9%80%89%E6%8B%A9%E6%9F%90%E4%B8%AA%E9%98%88%E5%80%BC%E6%9D%A5%E5%B0%86%E5%9C%86%E5%BD%A2%E7%82%B9%E5%92%8C%E6%96%B9%E5%BD%A2%E7%82%B9%E5%88%86%E5%BC%80%E3%80%82AdaBoost%E9%9C%80%E8%A6%81%E5%B0%86%E5%A4%9A%E4%B8%AA%E5%8D%95%E5%B1%82%E5%86%B3%E7%AD%96%E6%A0%91%E7%BB%84%E5%90%88%E8%B5%B7%E6%9D%A5%E6%89%8D%E8%83%BD%E5%AF%B9%E8%AF%A5%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E6%AD%A3%E7%A1%AE%E5%88%86%E7%B1%BB.jpg)\n",
    "用于检测AdaBoost构建函数的简单数据。这不可能仅仅通过在某个坐标轴上选择某个阈值来将圆形点和方形点分开。AdaBoost需要将多个单层决策树组合起来才能对该数据集进行正确分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T13:50:13.032704Z",
     "start_time": "2018-07-14T13:50:13.029703Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "dataMat, classLabels = loadSimpData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**构建单层决策树伪代码**：  \n",
    "　将最小错误率minError设为+∞  \n",
    "　对数据集中的每一个特征(第一层循环)：  \n",
    "　　对每个步长(第二层循环)：  \n",
    "　　　对每个不等号(第三层循环)：  \n",
    "　　　　建立一棵单层决策树并利用加权数据集对它进行测试  \n",
    "　　　　如果错误率低于minError，则将当前单层决策树设为最佳单层决策树  \n",
    "　返回最佳单层决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T07:00:32.048231Z",
     "start_time": "2018-07-15T07:00:32.040227Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# 单层决策树生成函数\n",
    "def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):  # just classify the data\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0], 1))\n",
    "    if threshIneq == 'lt':\n",
    "        retArray[dataMatrix[:, dimen] <= threshVal] = -1.0\n",
    "    else:\n",
    "        retArray[dataMatrix[:, dimen] > threshVal] = -1.0\n",
    "    return retArray\n",
    "\n",
    "\n",
    "def buildStump(dataArr, classLabels, D):\n",
    "    dataMatrix = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels).T\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    numSteps = 10.0\n",
    "    bestStump = {}\n",
    "    bestClasEst = np.mat(np.zeros((m, 1)))\n",
    "    minError = np.inf  # init error sum, to +infinity\n",
    "    for i in range(n):  # loop over all dimensions\n",
    "        rangeMin = dataMatrix[:, i].min()\n",
    "        rangeMax = dataMatrix[:, i].max()\n",
    "        stepSize = (rangeMax-rangeMin)/numSteps\n",
    "        for j in range(-1, int(numSteps)+1):  # loop over all range in current dimension\n",
    "            for inequal in ['lt', 'gt']:  # go over less than and greater than\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                # call stump classify with i, j, lessThan\n",
    "                predictedVals = stumpClassify(\n",
    "                    dataMatrix, i, threshVal, inequal)\n",
    "                errArr = np.mat(np.ones((m, 1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr  # calc total error multiplied by D\n",
    "                # print \"split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f\" % (i, threshVal, inequal, weightedError)\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump, minError, bestClasEst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**stumpClassify()是通过阈值比较对数据进行分类的**。所有在阈值一边的数据会分到类别-1，而在另外一边的数据分到类别+1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "buildStump()将会遍历stumpClassify()函数所有的可能输入值，并找到数据集上最佳的单层决策树。**这里的“最佳”是基于数据的权重向量D来定义的**。bestStump的字典用于存储给定权重向量D时所得到的最佳单层决策树的相关信息。变量numSteps用于在特征的所有可能值上进行遍历。变量minError用于寻找可能的最小错误率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "第一层for循环在数据集的所有特征上遍历。考虑到**数值型的特征，可以通过计算最小值和最大值来了解应该需要多大的步长**。然后，第二层for循环再在这些值上遍历。甚至将阈值设置为整个取值范围之外也是可以的。最后一个for循环则是在大于和小于之间切换不等式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "在嵌套的三层for循环之内，在数据集及三个循环变量上调用stumpClassify()函数。**基于这些循环变量，该函数将会返回分类预测结果**。将错误向量errArr和权重向量D的相应元素相乘并求和，就得到了数值**weightedError。这就是AdaBoost和分类器交互的地方**。这里是**基于权重向量D而不是其他错误计算指标来评价分类器的**。  \n",
    "最后，将当前的错误率与已有的最小错误率进行对比，如果当前的值较小，那么就在字典bestStump中保存该单层决策树。字典、错误率和类别估计值都会返回给AdaBoost算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T13:50:29.466369Z",
     "start_time": "2018-07-14T13:50:29.445355Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 1.3, 'ineq': 'lt'}, matrix([[0.2]]), array([[-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.mat(np.ones((5, 1))/5)\n",
    "buildStump(dataMat, classLabels, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "思考一下，该词典是否对应了最小可能的加权错误率？是否存在其他的设置也能得到相同的错误率？  \n",
    "上述单层决策树的生成函数是决策树的一个简化版本。它就是所谓的弱学习器，即弱分类算法。到现在为止，已经构建了单层决策树，下面将使用多个弱分类器来构建完整AdaBoost代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 完整AdaBoost算法的实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "**上一节构建了一个基于加权输入值进行决策的分类器**。  \n",
    "AdaBoost实现的伪代码如下：  \n",
    "　对每次迭代：  \n",
    "　　利用buildStump()函数找到最佳的单层决策树  \n",
    "　　将最佳单层决策树加入到单层决策树数组  \n",
    "　　计算alpha  \n",
    "　　计算新的权重向量D  \n",
    "　　更新累计类别估计值  \n",
    "　　如果错误率等于0.0，则退出循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T07:00:07.991374Z",
     "start_time": "2018-07-15T07:00:07.984370Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# 基于单层决策树的AdaBoost训练过程\n",
    "def adaBoostTrainDS(dataArr, classLabels, numIt=40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m, 1))/m)  # init D to all equal\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump, error, classEst = buildStump(\n",
    "            dataArr, classLabels, D)  # build Stump\n",
    "        #print(\"D:\", D.T)\n",
    "        # calc alpha, throw in max(error,eps) to account for error=0\n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error, 1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)  # store Stump Params in Array\n",
    "        #print(\"classEst: \", classEst.T)\n",
    "        # exponent for D calc, getting messy\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T, classEst)\n",
    "        D = np.multiply(D, np.exp(expon))  # Calc New D for next iteration\n",
    "        D = D/D.sum()\n",
    "        # calc training error of all classifiers, if this is 0 quit for loop early (use break)\n",
    "        aggClassEst += alpha*classEst\n",
    "        #print(\"aggClassEst: \", aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) !=\n",
    "                                np.mat(classLabels).T, np.ones((m, 1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        #print(\"total error: \", errorRate)\n",
    "        if errorRate == 0.0:\n",
    "            break\n",
    "    return weakClassArr, aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T14:40:50.235899Z",
     "start_time": "2018-07-14T14:40:50.220889Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst:  [[-1.  1. -1. -1.  1.]]\n",
      "aggClassEst:  [[-0.69314718  0.69314718 -0.69314718 -0.69314718  0.69314718]]\n",
      "total error:  0.2\n",
      "D: [[0.5   0.125 0.125 0.125 0.125]]\n",
      "classEst:  [[ 1.  1. -1. -1. -1.]]\n",
      "aggClassEst:  [[ 0.27980789  1.66610226 -1.66610226 -1.66610226 -0.27980789]]\n",
      "total error:  0.2\n",
      "D: [[0.28571429 0.07142857 0.07142857 0.07142857 0.5       ]]\n",
      "classEst:  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst:  [[ 1.17568763  2.56198199 -0.77022252 -0.77022252  0.61607184]]\n",
      "total error:  0.0\n"
     ]
    }
   ],
   "source": [
    "classifierArray = adaBoostTrainDS(dataMat, classLabels, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "AdaBoost算法的输入参数包括数据集、类别标签以及迭代次数numIt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "函数名称尾部的DS代表的就是单层决策树(decision stump)，它是AdaBoost中最流行的弱分类器，当然并非唯一可用的弱分类器。  \n",
    "向量D非常重要，它包含了每个数据点的权重。一开始，这些权重都赋予了相等的值。在后续的迭代中，**AdaBoost算法会在增加错分数据的权重的同时，降低正确分类数据的权重。**D是一个概率分布向量，因此其所有的元素之和为1.0。**列向量aggClassEst，记录每个数据点的类别估计累计值。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "AdaBoost算法的核心在于for循环，该循环运行numIt次或者直到训练错误率为0为止。利用buildStump()函数建立一个单层决策树。该函数的输入为权重向量D，返回的则是利用D而得到的具有最小错误率的单层决策树，同时返回的还有最小的错误率以及估计的类别向量。  \n",
    "接下来，需要计算的则是alpha值。该值会告诉总分类器本次单层决策树输出结果的权重。其中的语句**max(error 1e-16)用于确保在没有错误时不会发生除零溢出。**而后，alpha值加入到bestStump字典中，该词典包括了分类所需要的所有信息。  \n",
    "接下来计算下一次迭代中的新权重向量D。在训练错误率为0时，就要提前结束for循环。此时程序是通过aggClassEst变量保持一个运行时的类别估计值来实现的。该值只是一个浮点数，为了得到二值分类结果还需要调用sign()函数。如果总错误率为0，则由break语句中止for循环。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "在第一轮迭代中，D中的所有值都相等。于是，只有第一个数据点被错分了。因此在第二轮迭代中，D向量给第一个数据点0.5的权重。这就可以通过变量aggClassEst的符号来了解总的类别。第二次迭代之后，最后一个数据点却是错分了。D向量中的最后一个元素变成0.5，而D向量中的其他值都变得非常小。最后，第三次迭代之后aggClassEst所有值的符号和真实类别标签都完全吻合，那么训练错误率为0，程序就此退出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T14:40:43.514502Z",
     "start_time": "2018-07-14T14:40:43.510500Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 1.3, 'ineq': 'lt', 'alpha': 0.6931471805599453},\n",
       " {'dim': 1, 'thresh': 1.0, 'ineq': 'lt', 'alpha': 0.9729550745276565},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.8958797346140273}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试算法：基于AdaBoost的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "一旦拥有了多个弱分类器以及其对应的alpha值，进行测试就变得相当容易了。每个弱分类器的结果以其对应的alpha值作为权重。所有这些弱分类器的结果加权求和就得到了最后的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:09:46.693005Z",
     "start_time": "2018-07-14T15:09:46.689003Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# AdaBoost分类函数\n",
    "def adaClassify(datToClass, classifierArr):\n",
    "    # do stuff similar to last aggClassEst in adaBoostTrainDS\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m, 1)))\n",
    "    for i in range(len(classifierArr)):\n",
    "        classEst = stumpClassify(dataMatrix, classifierArr[i]['dim'],\n",
    "                                 classifierArr[i]['thresh'],\n",
    "                                 classifierArr[i]['ineq'])  # call stump classify\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        #print(aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "adaClassify()函数就是利用训练出的多个弱分类器进行分类的函数。该函数的输入是由一个或者多个待分类样例datToClass以及多个弱分类器组成的数组classifierArr。接下来，遍历classifierArr中的所有弱分类器，并基于stumpClassify()对每个分类器得到一个类别的估计值。输出的类别估计值乘上该单层决策树的alpha权重然后累加到aggClassEst上。最后，程序返回aggClassEst的符号，即如果aggClassEst大于0则返回+1，而如果小于0则返回-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T14:55:03.669016Z",
     "start_time": "2018-07-14T14:55:03.664014Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69314718]]\n",
      "[[-1.66610226]]\n",
      "[[-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[-1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0, 0], classifierArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T14:55:57.156959Z",
     "start_time": "2018-07-14T14:55:57.150955Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.69314718]\n",
      " [-0.69314718]]\n",
      "[[ 1.66610226]\n",
      " [-1.66610226]]\n",
      "[[ 2.56198199]\n",
      " [-2.56198199]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.],\n",
       "        [-1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([[5, 5], [0, 0]], classifierArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "分类结果也会随着迭代的进行而越来越强。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 示例：在一个难数据集上应用AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "本节将在第4章给出的马疝病数据集上应用AdaBoost分类器。想知道如果利用多个单层决策树和AdaBoost能不能预测得更准。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "|示例：在一个难数据集上的AdaBoost应用||\n",
    "|:-|:-|\n",
    "|收集数据|提供的文本文件|\n",
    "|准备数据|确保类别标签是+1和-1而非1和0|\n",
    "|分析数据|手工检查数据|\n",
    "|训练算法|在数据上，利用adaBoostTrainDS()函数训练出一系列的分类器|\n",
    "|测试算法|拥有两个数据集。在不采用随机抽样的方法下，我们就会对AdaBoost和Logistic回归的结果进行完全对等的比较|\n",
    "|使用算法|观察该例子上的错误率。不过，也可以构建一个Web网站，让驯马师输入马的症状然后预测马是否会死去|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T07:04:08.547036Z",
     "start_time": "2018-07-15T07:04:08.543032Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# 自适应数据加载函数\n",
    "def loadDataSet(fileName):  # general function to parse tab -delimited floats\n",
    "    # get number of fields\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat-1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat, labelMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:04:02.412982Z",
     "start_time": "2018-07-14T15:04:02.404977Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "该函数也假定最后一个特征是类别标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:13:27.115534Z",
     "start_time": "2018-07-14T15:13:26.823504Z"
    },
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArr, labelArr = loadDataSet('horseColicTraining2.txt')\n",
    "classifierArray = adaBoostTrainDS(dataArr, labelArr, 10)\n",
    "testArr, testLabelArr = loadDataSet('horseColicTest2.txt')\n",
    "prediction10 = adaClassify(testArr, classifierArray)\n",
    "errArr = np.mat(np.ones((67, 1)))\n",
    "errArr[prediction10 != np.mat(testLabelArr).T].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-14T15:15:05.979223Z",
     "start_time": "2018-07-14T15:15:05.974721Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "|分类器数目|训练错误率5|测试错误率%|\n",
    "|:-|:-|:-|\n",
    "|1|0.28|0.27|\n",
    "|10|0.23|0.24|\n",
    "|50|0.19|0.21|\n",
    "|100|0.19|0.22|\n",
    "|500|0.16|0.25|\n",
    "|1000|0.14|0.31|\n",
    "|10000|0.11|0.33|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "上面测试错误率达到一个最小值后又开始上升了，称为过拟合现象。有文献称**对于表现好的数据集，AdaBoost的测试错误率会达到一个稳定值，并不会随分类器增多而上升**。该数据集一开始有30%数据缺失，缺失值假设为0对决策树可能并不合适。或许考研替换成给定类别平均值，能得到更好性能吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "很多人都认为，AdaBoost和SVM是监督机器学习中最强大的两种方法。实际上，可以把弱分类器想象成SVM中的一个核函数，也可以按照最大化某个最小间隔的方式重写AdaBoost算法。而它们的不同就在于其所定义的间隔计算方式有所不同，特别是在高维空间下，这两者之间的差异就会更加明显。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 非均衡分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "在前面六章的所有分类介绍中，我们都假设所有类别的分类代价是一样的。  \n",
    "坦白地说，在大多数情况下不同类别的分类代价并不相等。在本节中，我们将会考察一种**新的分类器性能度量方法**，并通过图像技术来对在上述非均衡问题下不同分类器的性能进行可视化处理。然后，我们考察这两种分类器的变换算法，它们能够将不同决策的代价考虑在内。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 其他分类性能度量指标：正确率、召回率及ROC曲线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "到现在为止，本书都是基于错误率来衡量分类器任务的成功程度的。实际上，这样的度量错误掩盖了样例如何被分错的事实。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "一个三类问题混淆矩阵\n",
    "![表7-2](https://github.com/tw19941212/Graph-bed/raw/master/%E8%A1%A87-2%20%E4%B8%80%E4%B8%AA%E4%B8%89%E7%B1%BB%E9%97%AE%E9%A2%98%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "用混淆矩阵就可以更好地理解分类中的错误了。如果矩阵中的非对角元素均为0，就会得到一个完美的分类器。  \n",
    "接下来考虑另外一个混淆矩阵，这次的矩阵只针对一个简单的二类问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "一个两类问题混淆矩阵\n",
    "![表7-3](https://github.com/tw19941212/Graph-bed/raw/master/%E8%A1%A87-3%E4%B8%80%E4%B8%AA%E4%BA%8C%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "在分类中，当某个类别的重要性高于其他类别时，我们就可以利用上述定义来定义出多个比错误率更好的新指标。第一个指标是**正确率(Precision)**，它等于$TP/(TP+FP)$，给出的是预测为正例的样本中的真正正例的比例。第二个指标是**召回率(Recall)**，它等于$TP/(TP+FN)$，给出的是预测为正例的真实正例占所有真实正例的比例。在召回率很大的分类器中，真正判错的正例的数目并不多。  \n",
    "我们可以很容易构造一个高正确率或高召回率的分类器，但是很难同时保证两者成立。构建一个同时使正确率和召回率最大的分类器是具有挑战性的。  \n",
    "另一个用于度量分类中的非均衡性的工具是**ROC曲线(ROC curve)**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "![图7-3](https://github.com/tw19941212/Graph-bed/raw/master/%E5%9B%BE7-3%20%E5%88%A9%E7%94%A810%E4%B8%AA%E5%8D%95%E5%B1%82%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84AdaBoost%E9%A9%AC%E7%96%9D%E7%97%85%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F%E7%9A%84ROC%E6%9B%B2%E7%BA%BF.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "横轴是伪正例的比例(假阳率=FP/(FP+TN))，而纵轴是真正例的比例(真阳率=TP/(TP+FN))。**ROC曲线给出的是当阈值变化时假阳率和真阳率的变化情况**。左下角的点所对应的是将所有样例判为反例的情况，而右上角的点对应的则是将所有样例判为正例的情况。虚线给出的是随机猜测的结果曲线。  \n",
    "ROC曲线不但可以用于比较分类器，还可以基于成本效益(cost-versus-benefit)分析来做出决策。由于在不同的阈值下，不同的分类器的表现情况可能各不相同，因此以某种方式将它们组合起来或许会更有意义。如果只是简单地观察分类器的错误率，那么我们就难以得到这种更深入的洞察效果了。  \n",
    "在理想的情况下，**最佳的分类器应该尽可能地处于左上角**，这就意味着分类器在假阳率很低的同时获得了很高的真阳率。  \n",
    "对不同的ROC曲线进行比较的一个指标是曲线下的面积(Area Unser the Curve，AUC)。AUC给出的是分类器的平均性能值，当然它并不能完全代替对整条曲线的观察。一个完美分类器的AUC为1.0，而随机猜测的AUC则为0.5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "为了画出ROC曲线，分类器必须提供每个样例被判为阳性或者阴性的可信程度值---朴素贝叶斯能够提供一个可能性，而在Logistic回归中输入到Sigmoid函数中的是一个数值。在AdaBoost和SVM中，都会计算出一个数值然后输入到sign()函数中。所有的这些值都可以用于衡量给定分类器的预测强度。  \n",
    "为了创建ROC曲线，首先要将分类样例按照其预测强度排序。先从排名最低的样例开始，所有排名更低的样例都被判为反例，而所有排名更高的样例都被判为正例。该情况的对应点为<1.0,1.0>。然后，将其移到排名次低的样例中去，如果该样例属于正例，那么对真阳率进行修改；如果该样例属于反例，那么对假阴率进行修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T07:05:26.492146Z",
     "start_time": "2018-07-15T07:05:26.486142Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# ROC曲线的绘制及AUC计算函数\n",
    "def plotROC(predStrengths, classLabels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    cur = (1.0, 1.0)  # cursor\n",
    "    ySum = 0.0  # variable to calculate AUC\n",
    "    numPosClas = sum(np.array(classLabels) == 1.0)\n",
    "    yStep = 1/float(numPosClas)\n",
    "    xStep = 1/float(len(classLabels)-numPosClas)\n",
    "    sortedIndicies = predStrengths.argsort()  # get sorted index, it's reverse\n",
    "    fig = plt.figure()\n",
    "    fig.clf()\n",
    "    ax = plt.subplot(111)\n",
    "    # loop through all the values, drawing a line segment at each point\n",
    "    for index in sortedIndicies.tolist()[0]:\n",
    "        if classLabels[index] == 1.0:\n",
    "            delX = 0\n",
    "            delY = yStep\n",
    "        else:\n",
    "            delX = xStep\n",
    "            delY = 0\n",
    "            ySum += cur[1]\n",
    "        # draw line from cur to (cur[0]-delX,cur[1]-delY)\n",
    "        ax.plot([cur[0], cur[0]-delX], [cur[1], cur[1]-delY], c='b')\n",
    "        cur = (cur[0]-delX, cur[1]-delY)\n",
    "    ax.plot([0, 1], [0, 1], 'b--')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve for AdaBoost horse colic detection system')\n",
    "    ax.axis([0, 1, 0, 1])\n",
    "    plt.show()\n",
    "    print(\"the Area Under the Curve is: \", ySum*xStep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "plotROC()第一个参数是一个NumPy数组或者一个行向量组成的矩阵。**该参数代表的则是分类器的预测强度。在分类器和训练函数将这些数值应用到sign()函数之前就已经产生了。**cur初始化为（1,0,1.0）。该元组保留的是绘制光标的位置，变量ySum则用于计算AUC的值。numPosClas通过数组过滤方式计算正例的数目。因此y轴上的步长是1.0／numPosClas。类似地，就可以得到x轴的步长了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "排序索引按照最小到最大的顺序排列的，因此我们需要从点<1.0,1.0>开始绘，一直到<0,0>。Python则需要一个表来进行迭代循环，因此我们需要调用tolist()方法。当遍历表时，每得到一个标签为1.0的类，则要沿着y轴的方向下降一个步长，即不断降低真阳率。类似地，对于每个其他类别的标签，则是在x轴方向上倒退了一个步长(假阴率方向)。**上述代码只关注1这个类别标签，因此就无所谓是采用1/0标签还是+1/-1标签。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "为了计算AUC，我们需要对多个小矩形的面积进行累加。这些小矩形的宽度是xStep，因此可以先对所有矩形的高度进行累加(ySum)，最后再乘以xStep得到其总面积。一旦决定了是在x轴还是y轴方向上进行移动的，我们就可以在当前点和新点之间画出一条线段。然后，当前点cur更新了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T06:59:36.541729Z",
     "start_time": "2018-07-15T06:59:36.537727Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "为了解实际运行效果，我们需要将adaboostTrainDS()的最后一行代码替换成：return weakClassArr,aggClassEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T07:09:56.362642Z",
     "start_time": "2018-07-15T07:09:53.612254Z"
    },
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Area Under the Curve is:  0.8582969635063604\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the Area Under the Curve is:  0.8953941870182941\n"
     ]
    }
   ],
   "source": [
    "dataArr, labelArr = loadDataSet('horseColicTraining2.txt')\n",
    "classifierArray, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 10)\n",
    "plotROC(aggClassEst.T, labelArr)\n",
    "classifierArray, aggClassEst = adaBoostTrainDS(dataArr, labelArr, 50)\n",
    "plotROC(aggClassEst.T, labelArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "对比10个弱分类器下和50个弱分类器，AdaBoost算法性能的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 基于代价函数的分类器决策控制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "除了调节分类器的阈值之外，我们还有一些其他可以用于处理非均衡分类的代价的方法，其中的一种称为代价敏感的学习(cost-sensitive learning)。如果在**构建分类器时，知道了这些代价值，那么就可以选择付出最小代价的分类器**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "![表7-4](https://github.com/tw19941212/Graph-bed/raw/master/%E8%A1%A87-4%E4%B8%80%E4%B8%AA%E4%BA%8C%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E4%BB%A3%E4%BB%B7%E7%9F%A9%E9%98%B5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "第一张表给出的是到目前为止分类器的代价矩阵(代价不是0就是1)。我们可以基于该代价矩阵计算其总代价：$TP*0+FN*1+FP*1+TN*0$。接下来我们考虑下面的第二张表，基于该代价矩阵的分类代价的计算公式为：$TP*(-5)+FN*1+FP*50+TN*0$。**采用第二张表作为代价矩阵时，两种分类错误的代价是不一样的。类似地，这两种正确分类所得到的收益也不一样。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "在分类算法中，我们有很多方法可以用来引入代价信息---在AdaBoost中，可以基于代价函数来调整错误权重向量D。在朴素贝叶斯中，可以选择具有最小期望代价而不是最大概率的类别作为最后的结果。在SVM中，可以在代价函数中对于不同的类别选择不同的参数C。**上述做法就会给较小类更多的权重，即在训练时，小类当中只允许更少的错误。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "### 处理非均衡问题的数据抽样方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "另外一种针对非均衡问题调节分类器的方法，就是对分类器的训练数据进行改造。这可以通过欠抽样(undersampling)或者过抽样(oversampling)来实现。过抽样意味着复制样例，而欠抽样意味着删除样例。不管采用哪种方式，数据都会从原始形式改造为新形式。**抽样过程则可以通过随机方式或者某个预定方式来实现。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "欠抽样方法的一个缺点就在于要确定哪些样例需要进行剔除。但是，在选择剔除的样例中可能携带了剩余样例中并不包含的有价值信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "上述问题的一种解决办法，就是选择那些离决策边界较远的样例进行删除。有一种替代的策略就是使用反例类别的欠抽样和正例类别的过抽样相混合的方法。  \n",
    "要对正例类别进行过抽样，我们可以复制已有样例或者加入与已有样例相似的点。一种方法是加入已有数据点的插值点，**但是这种做法可能会导致过拟合的问题。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "## 本章小结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "集成方法通过组合多个分类器的分类结果，获得了比简单的单分类器更好的分类结果。本章只介绍了那些**利用同一类分类器的集成方法。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "多个分类器组合可能会进一步凸显出单分类器的不足，比如过拟合问题。**如果分类器之间差别显著，那么多个分类器组合就可能会缓解这一问题**。分类器之间的差别可以是算法本身或者是应用于算法上的数据的不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "bagging和boosting。在bagging中，是通过随机抽样的替换方式，得到了与原始数据集规模一样的数据集。而boosting在bagging的思路上更进了一步，它在数据集上顺序应用了多个不同的分类器。另一个成功的集成方法就是随机森林，但是由于随机森林不如AdaBoost流行，所以在此并没有对它进行介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "介绍了boosting方法中最流行的一个称为AdaBoost的算法。AdaBoost以弱学习器作为基分类器，并且输入数据，使其通过权重向量进行加权。在第一次迭代当中，所有数据都等权重。但是在后续的迭代当中，前次迭代中分错的数据的权重会增大。**这种针对错误的调节能力正是AdaBoost的长处。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "以单层决策树作为弱学习器构建了AdaBoost分类器。实际上，**AdaBoost函数可以应用于任意分类器，只要该分类器能够处理加权数据即可**。AdaBoost算法十分强大，它能够快速处理其他分类器很难处理的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "非均衡分类问题是指在分类器训练时正例数目和反例数目不相等(相差很大)。该问题在错分正例和反例的代价不同时也存在。本章不仅考察了一种不同分类器的评价方法---ROC曲线，还介绍了正确率和召回率这两种在类别重要性不同时度量分类器性能的指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "本章介绍了通过过抽样和欠抽样方法来调节数据集中的正例和反例数目。另外一种可能更好的非均衡问题的处理方法，就是在训练分类器时将错误的代价考虑在内。"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 207,
   "position": {
    "height": "812px",
    "left": "1531px",
    "right": "20px",
    "top": "75px",
    "width": "369px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
